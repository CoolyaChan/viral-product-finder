import streamlit as st
import pandas as pd
import scraper  # ç¢ºä¿èˆ‡æ‚¨çš„ scraper.py åœ¨åŒä¸€å±¤ç´š
import time

# --- ç¶²é é…ç½® ---
st.set_page_config(
    page_title="å…¨çƒé›»å•†å³æ™‚çˆ†å“è©•æ¯”",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# --- è‡ªå®šç¾©æ¨£å¼ ---
st.markdown("""
    <style>
    .stDataFrame { border: 1px solid #e6e9ef; border-radius: 10px; }
    .stMetric { background-color: #ffffff; border-radius: 10px; padding: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    </style>
    """, unsafe_allow_html=True)

# --- ä¸»ç•«é¢æ¨™é¡Œ ---
st.title("ğŸ›¡ï¸ å…¨çƒé›»å•†å³æ™‚æ•¸æ“šç›£æ§ä¸­å¿ƒ")
st.markdown("æœ¬ç³»çµ±æ˜¯æ ¹æ“šæ‚¨çš„é—œéµå­—**å³æ™‚å°å…¨çƒå¹³å°ç™¼å‹•æª¢ç´¢**ã€‚")

# --- å´é‚Šæ¬„ï¼šåŠŸèƒ½é¸å–® ---
st.sidebar.header("ğŸ¯ æœå°‹é…ç½®")
selected_platforms = st.sidebar.multiselect(
    "åŒ…å«å¹³å°",
    ["momo", "PChome", "Amazon", "eBay", "1688", "æ·˜å¯¶"],
    default=["momo", "PChome", "Amazon", "eBay", "1688", "æ·˜å¯¶"]
)

st.sidebar.divider()
st.sidebar.info("ğŸ’¡ æç¤ºï¼šè¼¸å…¥å…·é«”å•†å“åç¨±ï¼ˆå¦‚ï¼šç­‹è†œæ§ï¼‰æ¯”æ¨¡ç³Šè©ï¼ˆå¦‚ï¼šé›»ï¼‰æ•ˆæœæ›´å¥½ã€‚")

# --- æœå°‹è¼¸å…¥å€ ---
search_query = st.text_input("ğŸ” è«‹è¼¸å…¥æ‚¨æƒ³è©•æ¯”çš„å•†å“é—œéµå­—ï¼š", placeholder="ä¾‹å¦‚ï¼šè¡Œå‹•é›»æºã€éœ²ç‡Ÿæ‘ºç–Šæ¡Œã€è‡ªå‹•è²“ç ‚ç›†...")

if search_query:
    # å»ºç«‹æœå°‹å‹•ç•«
    with st.spinner(f"æ­£åœ¨é€£ç·šå…¨å¹³å° API ä¸¦æª¢ç´¢ã€Œ{search_query}ã€çš„å³æ™‚è¡Œæƒ…..."):
        # èª¿ç”¨ scraper.py ä¸­çš„ fetch_all_platforms å‡½æ•¸
        try:
            raw_results = scraper.fetch_all_platforms(search_query)
            
            if raw_results:
                df = pd.DataFrame(raw_results)
                
                # æ ¹æ“šå´é‚Šæ¬„é¸æ“‡çš„å¹³å°é€²è¡Œéæ¿¾
                filtered_df = df[df['å¹³å°'].isin(selected_platforms)]
                
                if not filtered_df.empty:
                    # --- æ•¸æ“šå±•ç¤ºå€ ---
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.subheader(f"ğŸ“Š ã€Œ{search_query}ã€å…¨å¹³å°æ•¸æ“šåˆ†æ")
                        st.dataframe(
                            filtered_df.sort_values(by="ç†±åº¦", ascending=False),
                            column_config={
                                "å¹³å°": st.column_config.TextColumn("ä¾†æºå¹³å°"),
                                "å“å": st.column_config.TextColumn("å®Œæ•´å“å", width="large"),
                                "ç†±åº¦": st.column_config.ProgressColumn("çˆ†å“æ½›åŠ›è©•åˆ†", format="%dåˆ†", min_value=0, max_value=100),
                                "é¡åˆ¥": st.column_config.TextColumn("æ¨™ç±¤")
                            },
                            hide_index=True,
                            use_container_width=True
                        )
                    
                    with col2:
                        st.subheader("ğŸ“ˆ å¹³å°ç†±åº¦å°æ¯”")
                        avg_heat = filtered_df.groupby('å¹³å°')['ç†±åº¦'].mean().reset_index()
                        st.bar_chart(avg_heat.set_index('å¹³å°'))
                        
                        max_item = filtered_df.loc[filtered_df['ç†±åº¦'].idxmax()]
                        st.metric("ç•¶å‰æœ€é«˜ç†±åº¦", f"{max_item['ç†±åº¦']}åˆ†", f"ä¾†è‡ª {max_item['å¹³å°']}")

                else:
                    st.warning("âš ï¸ æ‚¨é¸æ“‡çš„å¹³å°ç›®å‰ç„¡ç›¸é—œæœå°‹çµæœï¼Œè«‹å˜—è©¦å‹¾é¸æ›´å¤šå¹³å°ã€‚")
            else:
                st.error("âŒ æŠ±æ­‰ï¼Œç›®å‰æ‰€æœ‰å¹³å°çš†æœªå›å‚³æ•¸æ“šï¼Œå¯èƒ½æ˜¯è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        except Exception as e:
            st.error(f"ç³»çµ±åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
            st.info("è«‹æª¢æŸ¥ scraper.py æª”æ¡ˆæ˜¯å¦èˆ‡ app.py æ”¾åœ¨ä¸€èµ·ï¼Œä¸” requirements.txt å·²å®‰è£å¿…è¦å¥—ä»¶ã€‚")

else:
    # åˆå§‹æ­¡è¿ç•«é¢
    st.divider()
    col_a, col_b, col_c = st.columns(3)
    col_a.markdown("### 1. è¼¸å…¥åç¨±\nè¼¸å…¥æ‚¨æ„Ÿèˆˆè¶£çš„ä»»ä½•å•†å“åç¨±ã€‚")
    col_b.markdown("### 2. å³æ™‚çˆ¬å–\nç³»çµ±æœƒç«‹åˆ»æ¨¡æ“¬çœŸäººå‰å¾€å„åœ‹é›»å•†ç¶²ç«™æŠ“å–ã€‚")
    col_c.markdown("### 3. ç¶œåˆè©•æ¯”\nè‡ªå‹•è¨ˆç®—å„å¹³å°çš„ç†±åº¦èˆ‡ç«¶çˆ­åŠ›ã€‚")
    
    st.image("https://images.unsplash.com/photo-1460925895917-afdab827c52f?auto=format&fit=crop&w=800&q=80", caption="Global E-commerce Data Analytics")

# --- é å°¾ ---
st.divider()
st.caption("ğŸ” æœ¬å·¥å…·åƒ…ä¾›ç ”ç©¶åƒè€ƒã€‚å¯¦æ™‚æ•¸æ“šå—å„å¹³å°ç¶²è·¯é™åˆ¶å½±éŸ¿ï¼Œæœå°‹çµæœå¯èƒ½æœ‰ 3-5 ç§’å»¶é²ã€‚")
